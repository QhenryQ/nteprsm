{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46aa49f-4c95-4444-8171-2529558bd3b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93849634-537c-43b0-9300-5207b4876f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from cmdstanpy import CmdStanModel\n",
    "import cmdstanpy\n",
    "import numpy as np\n",
    "from scipy.stats import invgamma\n",
    "from scipy.stats import norm\n",
    "from scipy.special import softmax\n",
    "from gptools.stan import get_include\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from nteprsm import utils \n",
    "from cmdstanpy import stanfit\n",
    "from settings import ROOT_DIR\n",
    "import plotly.express as px\n",
    "import utils as notebook_utils\n",
    "# use customize plotly template\n",
    "notebook_utils.set_custom_template()\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d30a7-c3b9-491a-a5bf-fb1fa4ddf150",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "def rbf_kernel_2D(x1, x2, length_scale=1.0, variance=1.0):\n",
    "    # Squared Euclidean distance\n",
    "    sqdist = np.sum((x1 - x2)**2)\n",
    "    return variance * np.exp(-0.5 * sqdist / length_scale**2)\n",
    "\n",
    "def generate_plot_effect_gaussian_process(grid_width, grid_height, length_scale=1.0, variance=1.0, mean=0.0):\n",
    "    # Create the grid\n",
    "    x = np.arange(grid_width)\n",
    "    y = np.arange(grid_height)\n",
    "    grid_points = np.array([[i, j] for i in x for j in y])  # All (x, y) pairs\n",
    "    n = len(grid_points)\n",
    "    \n",
    "    # Compute the covariance matrix\n",
    "    K = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            K[i, j] = rbf_kernel_2D(grid_points[i], grid_points[j], length_scale, variance)\n",
    "    \n",
    "    # Add a small value to the diagonal for numerical stability\n",
    "    K += 1e-6 * np.eye(n)\n",
    "    \n",
    "    # Sample from the multivariate Gaussian distribution\n",
    "    gp_values = np.random.multivariate_normal(mean * np.ones(n), K)\n",
    "    \n",
    "    # Reshape to a 2D grid\n",
    "    gp_grid = gp_values.reshape((grid_width, grid_height))\n",
    "    \n",
    "    return gp_grid\n",
    "\n",
    "def periodic_kernel(x1, x2, length_scale=1.0, variance=1.0, period=1.0):\n",
    "    \"\"\"Periodic kernel function for 1D inputs.\"\"\"\n",
    "    dist = np.abs(x1 - x2)\n",
    "    sin_term = np.sin(np.pi * dist / period)  # Sinusoidal periodicity\n",
    "    return variance * np.exp(-2 * (sin_term**2) / length_scale**2)\n",
    "\n",
    "def generate_1d_gaussian_process(extra_points = 0, length_scale=1.0, variance=1.0, period=1.0, inp_arr = [], mean = 0.0, force_mean = True):\n",
    "    \"\"\"Generate a 1D Gaussian Process with a periodic kernel.\"\"\"\n",
    "    x = inp_arr.copy()\n",
    "    # Define the 1D grid\n",
    "    if extra_points > 1:\n",
    "        x.extend(list(np.linspace(0, 1, extra_points, endpoint=False)))  # Inputs evenly spaced between 0 and 1\n",
    "    x = np.array(x)\n",
    "    n = len(x)\n",
    "\n",
    "    assert n > 1\n",
    "\n",
    "    # Compute the covariance matrix\n",
    "    K = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            K[i, j] = periodic_kernel(x[i], x[j], length_scale, variance, period)\n",
    "    \n",
    "    # Add a small jitter for numerical stability\n",
    "    K += 1e-6 * np.eye(n)\n",
    "\n",
    "    # Sample from the multivariate Gaussian\n",
    "    gp_samples = np.random.multivariate_normal(mean * np.ones(n), K)\n",
    "\n",
    "    if force_mean: gp_samples = gp_samples - np.mean(gp_samples) + mean\n",
    "\n",
    "    assert len(gp_samples) == n\n",
    "    \n",
    "    return x, gp_samples\n",
    "\n",
    "def rsm_probability(y, theta, tau):\n",
    "    \"\"\"\n",
    "    Calculates the probability of a given class label in the model.\n",
    "\n",
    "    Args:\n",
    "    y (int): The class label for which the probability is calculated.\n",
    "    theta (np.ndarray): An array of model parameters.\n",
    "    tau (np.ndarry): The threshold parameters for the model.\n",
    "\n",
    "    Returns:\n",
    "    float: The probability of the given class label.\n",
    "\n",
    "    \"\"\"\n",
    "    unsummed = np.concatenate(([0], theta - tau))\n",
    "    probs = softmax(np.cumsum(unsummed))\n",
    "    return probs[y]\n",
    "\n",
    "def rsm_probability_vector(theta, tau):\n",
    "    \"\"\"\n",
    "    Calculates the probability of set of class labels in given model\n",
    "\n",
    "    Args:\n",
    "    theta (np.ndarray): An array of model parameters.\n",
    "    tau (np.ndarry): The threshold parameters for the model.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array probability of given class label.\n",
    "    \"\"\"\n",
    "    unsummed = np.concatenate(([0], theta - tau))\n",
    "    probs = softmax(np.cumsum(unsummed))\n",
    "    return probs\n",
    "\n",
    "def plot_rater_characteristic_curve(\n",
    "        taus,\n",
    "        min_theta=-6,\n",
    "        max_theta=6,\n",
    "        resolution=500,\n",
    "        colors=px.colors.diverging.Spectral,\n",
    "        dimensions=None,\n",
    "    ) -> go.Figure:\n",
    "        \"\"\"\n",
    "        Plot the characteristic curves for raters based on the fitted Stan model.\n",
    "\n",
    "        Args:\n",
    "            rater_id (int, optional): The rater ID to plot. If None, all raters\n",
    "                will be plotted. Defaults to None.\n",
    "            dimensions (tuple, optional): Dimensions of the plot as (width, height).\n",
    "\n",
    "        Returns:\n",
    "            A Plotly figure object containing the plotted characteristic curves.\n",
    "        \"\"\"\n",
    "        taus_with_bounds = np.concatenate(([min_theta], taus, [max_theta]))\n",
    "        x = np.linspace(min_theta, max_theta, int((max_theta - min_theta) * resolution))\n",
    "        num_categories = len(taus) + 1\n",
    "        fig = go.Figure()\n",
    "        for i in range(num_categories):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x,\n",
    "                    y=[rsm_probability(i, theta, taus) for theta in x],\n",
    "                    line=dict(width=2, color=colors[i]),\n",
    "                    name=str(i + 1),\n",
    "                )\n",
    "            )\n",
    "            fig.add_shape(\n",
    "                type=\"rect\",\n",
    "                x0=taus_with_bounds[i],\n",
    "                x1=taus_with_bounds[i + 1],\n",
    "                y0=1.02,\n",
    "                y1=1.1,\n",
    "                fillcolor=colors[i],\n",
    "            )\n",
    "            if i != num_categories - 1:\n",
    "                fig.add_shape(\n",
    "                    type=\"line\",\n",
    "                    x0=taus[i],\n",
    "                    x1=taus[i],\n",
    "                    y0=0,\n",
    "                    y1=1,\n",
    "                    line=dict(color=colors[i], dash=\"dot\"),\n",
    "                )\n",
    "\n",
    "        fig.update_layout(\n",
    "            xaxis_title=\"Turf Quality on Latent Scale\",\n",
    "            yaxis_title=\"Probability\",\n",
    "            legend=dict(x=1.02, y=1),\n",
    "        )\n",
    "        if dimensions:\n",
    "            fig.update_layout(width=dimensions[0], height=dimensions[1])\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aacbf10-9690-450a-8f8f-59e417762629",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Parameters for Parameter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9129ab-f7ec-47e9-bb1c-b4429b149a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustable parameters\n",
    "\n",
    "# base grid\n",
    "grid_size_x = 21\n",
    "grid_size_y = 21\n",
    "\n",
    "# spatial effect Gaussian Process\n",
    "lengthscale_plot = 3\n",
    "sigma_plot = 2\n",
    "\n",
    "# rating event generation\n",
    "num_raters = 5\n",
    "min_rating_events_per_rater = 5\n",
    "num_rating_events = num_raters * (min_rating_events_per_rater + 5)\n",
    "\n",
    "# seasonality Gaussian Process\n",
    "lengthscale_f = 2\n",
    "sigma_f = 2.0\n",
    "intercept_f_std = 2.0\n",
    "\n",
    "# rater beta parameters\n",
    "num_categories = 9\n",
    "min_threshold_spacing = 0.3\n",
    "max_threshold_spacing = 1.2\n",
    "\n",
    "# Sampling config\n",
    "config = {'data_path': 'data/raw/quality_nj2.csv',\n",
    " 'stan_file': 'models/nteprsm_turf_annual_seasonality.stan',\n",
    " 'stan_additional_data': {'M_f': 8, 'pred_N': 100, 'padding': 5},\n",
    " 'sampling': {'parallel_chains': 4,\n",
    "  'seed': 1,\n",
    "  'show_progress': True,\n",
    "  'adapt_delta': 0.99,\n",
    "  'max_treedepth': 15,\n",
    "  'refresh': 20,\n",
    "  'iter_warmup': 500,\n",
    "  'iter_sampling': 1500,\n",
    "  'save_warmup': True,\n",
    "  'output_dir': 'data/model_output',\n",
    "  'time_fmt': '%Y%m%d',\n",
    "  'show_console': True}}\n",
    "\n",
    "# filename to save the posterior samples under\n",
    "savename = 'param_recover_example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37047ef3-f1ba-4ac3-8354-f2f6beab90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generated basic parameters\n",
    "assert (grid_size_x * grid_size_y) % 3 == 0\n",
    "num_entries = grid_size_x * grid_size_y // 3\n",
    "\n",
    "plot_coordinates = [(x, y) for x in range(grid_size_x) for y in range(grid_size_y)]\n",
    "random.shuffle(plot_coordinates)\n",
    "\n",
    "# filepath for synthetic dataset\n",
    "filepath = ROOT_DIR/f\"{savename}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992bb0ce-d939-4fa8-b9e4-0becc9cb40e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Synthetic Spatial Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66be3a1-81b3-46d0-9b24-31a0fb7fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_grid = generate_plot_effect_gaussian_process(grid_size_x, grid_size_y, lengthscale_plot, sigma_plot**2)\n",
    "gp_grid = gp_grid - np.mean(gp_grid)\n",
    "\n",
    "# Visualization\n",
    "plt.imshow(gp_grid, cmap=\"viridis\", extent=(0, grid_size_x, 0, grid_size_y))\n",
    "plt.colorbar(label=\"GP Value\")\n",
    "plt.title(\"Plot effect GP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce0e9e-8670-43d5-92a1-3858a645cfe2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Synthetic Rating Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf454ecc-08d9-4294-bc53-3ec452ce5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_event_times = sorted([random.random() for i in range(num_rating_events)])\n",
    "## TODO : Adjust from march to november (?)\n",
    "\n",
    "raters = [\n",
    "    rater\n",
    "    for rater in range(num_raters)\n",
    "    for _ in range(min_rating_events_per_rater)\n",
    "]\n",
    "remaining_events = num_rating_events - (min_rating_events_per_rater * num_raters)\n",
    "raters += [random.randint(0, num_raters - 1) for _ in range(remaining_events)]\n",
    "random.shuffle(raters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0956f-f142-4ff9-8037-a38c63e194f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Define distinct colors for each rater\n",
    "colors = plt.cm.get_cmap(\"Set2\", num_raters).colors  # Get unique colors for raters\n",
    "\n",
    "# Plot each rater separately for better legend control\n",
    "for rater_id in range(num_raters):\n",
    "    indices = [i for i, r in enumerate(raters) if r == rater_id]\n",
    "    plt.scatter(\n",
    "        np.array(rating_event_times)[indices],  # Use existing event times\n",
    "        [raters[i] for i in indices], \n",
    "        color=colors[rater_id], \n",
    "        label=f\"Rater {rater_id}\", \n",
    "        edgecolors=\"k\", \n",
    "        alpha=1.0,\n",
    "        s = 50\n",
    "    )\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Rating Event Time (Normalized)\")  # Adjust based on your time format\n",
    "plt.ylabel(\"Rater ID\")\n",
    "plt.title(\"Synthetic Rating Events and Assigned Raters\")\n",
    "plt.yticks(range(num_raters))  # Ensure y-axis only shows valid rater IDs\n",
    "plt.legend(title=\"Raters\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")  # Move legend outside\n",
    "plt.grid()\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8827e96-b688-4f8c-9167-b6739124d4d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Synthetic Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59e344-344c-4803-86d2-5d9a2c290dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for illustration\n",
    "illustrated_entries = 5\n",
    "num_points = 0    # Extra points for illustration\n",
    "period = 1.0        # Period of the periodic kernel\n",
    "\n",
    "# gp_samples\n",
    "gp_samples = []\n",
    "print(\"Generating Gaussian Processes...\")\n",
    "print(\"|\"*illustrated_entries)\n",
    "for i in range(illustrated_entries):\n",
    "    intercept_f = norm.rvs(loc=0, scale=intercept_f_std)\n",
    "    x, gp = generate_1d_gaussian_process(num_points, lengthscale_f, sigma_f**2, period, rating_event_times, mean = intercept_f, force_mean = True)\n",
    "    gp_samples.append(gp)\n",
    "    print(\"|\", end = '')\n",
    "\n",
    "# Plot the Gaussian Process\n",
    "x_sorted = sorted(x)\n",
    "for i in range(illustrated_entries):\n",
    "    gp_samples_sorted = [z for _, z in sorted(zip(x, gp_samples[i]))]\n",
    "    plt.plot(x_sorted, gp_samples_sorted, label=f\"Entry {i}\")\n",
    "\n",
    "plt.title(\"Turfgrass Seasonality GP Samples\")\n",
    "plt.xlabel(\"Time of Year (Normalized)\")\n",
    "plt.ylabel(\"Synthetic Seasonality\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Generating the rest of the Gaussian Processes...\")\n",
    "print(\"|\"*(num_entries - illustrated_entries))\n",
    "for i in range(num_entries - illustrated_entries):\n",
    "    intercept_f = norm.rvs(loc = 0, scale = intercept_f_std)\n",
    "    x, gp = generate_1d_gaussian_process(num_points, lengthscale_f, sigma_f**2, period, rating_event_times, mean = intercept_f)\n",
    "    gp_samples.append(gp)\n",
    "    print(\"|\", end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d653a2-c0d1-44fe-a9c2-4aa09e2efcaf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Synthetic Rater Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3a758-7d63-4940-b8a1-0bd85b68eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = []\n",
    "\n",
    "for i in range(num_raters):\n",
    "    ## we want some reasonable looking thresholds\n",
    "    diffs = [0 for _ in range(num_categories - 2)]\n",
    "    while min(diffs) < min_threshold_spacing or max(diffs) > max_threshold_spacing:\n",
    "        thresholds = sorted([norm.rvs(loc=0, scale=2) for _ in range(num_categories - 1)])\n",
    "        diffs = [thresholds[i+1] - thresholds[i] for i in range(num_categories - 2)]\n",
    "    print(f\"Thresholds for rater {i}: {thresholds}\")\n",
    "    plot_rater_characteristic_curve(thresholds).show()\n",
    "    taus.append(thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e6eae-76b5-4bae-99fc-8dea26bf5929",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dbfe60-96cf-45df-a8f1-6c5302d7d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for r in range(num_rating_events):\n",
    "    rating_time = rating_event_times[r]\n",
    "    rater = raters[r]\n",
    "    for plot_id in range(len(plot_coordinates)):\n",
    "        entry_code = plot_id // 3 + 1\n",
    "        plot_row = plot_coordinates[plot_id][0] + 1\n",
    "        plot_col = plot_coordinates[plot_id][1] + 1\n",
    "        plot_effect = gp_grid[plot_row - 1][plot_col - 1]\n",
    "        turfgrass_seasonality = gp_samples[entry_code - 1][r]\n",
    "        theta = plot_effect + turfgrass_seasonality\n",
    "        probs = rsm_probability_vector(theta, taus[rater])\n",
    "        rating = np.random.choice(len(probs), size=1, p=probs)[0]\n",
    "        data.append({\n",
    "            \"entry_name\": entry_code,\n",
    "            \"plt_id\":plot_id,\n",
    "            \"row\": plot_row,\n",
    "            \"col\": plot_col,\n",
    "            \"rater\": rater,\n",
    "            \"rating_event\":str(r),\n",
    "            \"adj_time_of_year\": rating_time,\n",
    "            \"quality\": rating + 1,\n",
    "            ### for comparing outcomes\n",
    "            \"SEASONALITY\": turfgrass_seasonality,\n",
    "            \"PLOT_EFFECT\": plot_effect,\n",
    "            \"OUTCOME_PROBABILITY\": probs[rating],\n",
    "        })\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "df = df.assign(\n",
    "    entry_name_code=pd.Categorical(df[\"entry_name\"]).codes,\n",
    "    plt_id_code=pd.Categorical(df[\"plt_id\"]).codes,\n",
    "    rater_code=pd.Categorical(df[\"rater\"]).codes,\n",
    "    rating_event_code=pd.Categorical(df[\"rating_event\"]).codes,\n",
    ")\n",
    "df[\"entry_cumcount\"] = df.groupby(\"entry_name\").cumcount() + 1\n",
    "df.to_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165be4c8-09f8-4920-80d2-8c52ed82f6cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Posterior Sample Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a6862-6535-4f6e-b44e-517226e0418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datahandler = utils.DataHandler(filepath=filepath)\n",
    "datahandler.model_data = df\n",
    "datahandler.generate_stan_data(**config[\"stan_additional_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036a1f9-0ef2-4ebc-ad9e-f0e62f524543",
   "metadata": {},
   "outputs": [],
   "source": [
    "!install_cmdstan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4794bc-3ef3-411c-b70d-9e6167eb732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nteprsm = CmdStanModel(\n",
    "    stan_file=config[\"stan_file\"],\n",
    "    stanc_options={\"include-paths\": get_include()},\n",
    ")\n",
    "\n",
    "# samples will be saved in the csv files in the output directory specified in the config\n",
    "fit = nteprsm.sample(data=datahandler.stan_data, **config[\"sampling\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972fa7f-3aeb-454a-950b-4bf003061d5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Saving Posterior Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80dfd6-d89a-446f-b548-a628eeddb754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the fit object\n",
    "with open(f\"fit_{save_name}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fit, f)\n",
    "\n",
    "# Dump the df object\n",
    "with open(f'df_{save_name}.pkl', \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "with open(f'gpgrid_{save_name}.pkl', \"wb\") as f:\n",
    "    pickle.dump(gp_grid, f)\n",
    "\n",
    "with open(f'taus_{save_name}.pkl', \"wb\") as f:\n",
    "    pickle.dump(taus, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
