{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9dafb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c823e47-77f4-4af8-819c-02b1ec5fbe87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gptools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NTEPModel\n",
      "File \u001b[0;32m~/Documents/GitHub/ntep-rsm/src/model.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Imports for stan tools\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgptools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_model\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcmdstanpy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnest_asyncio\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gptools'"
     ]
    }
   ],
   "source": [
    "from src.model import NTEPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8417938-ba00-4373-9e55-8674292f2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the already fitted model\n",
    "m = NTEPModel(load_file='model_04-feb-2024-distinct_taus (rater_severity)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb99c3c-ab8f-4a8b-8e7c-716941321d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or sample the model, and then save it\n",
    "m = NTEPModel(num_basis_functions = 8,            # 8 by default\n",
    "                        stan_file = 'model_04-feb-2024-distinct_taus.stan', # (some predetermined filepath) by default\n",
    "                        data_file = 'quality_nj2.csv', # nj2 dataset by default\n",
    "                        pred_N = 100,                         # 100 by default\n",
    "                        padding = 5,)                         # 5 by default\n",
    "m.sample()\n",
    "m.save(file='model_04-feb-2024-distinct_taus (rater_severity)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d737b56-1b83-4fe3-b38c-7d27b729c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the model's convergence\n",
    "m.plot_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5565e-a6b1-4c32-8ecc-3c58222faadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot specific variables with plot_trace\n",
    "m.plot_trace(var_names=['rater_severity','tau_rater'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8fa21-7822-48b5-8ade-8906e7ff2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "m.plot_time_effect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e27da-d92b-4bdb-86fe-39cfb8d647b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_time_effect(entries=4, # plot N random entries\n",
    "                   credit_interval = 0.5, # credit interval\n",
    "                   sort_entries = 'data', # sort methods, accepts:  'unsorted', 'weighted', 'annual', 'data'\n",
    "                                        # data ranks by average of the points where we have taken ratings\n",
    "                                        # annual ranks by all predicted point\n",
    "                                        # weighted (default) uses all predicted points, but weights them according to the standard deviation of samples\n",
    "                                        # predictions near data points are weighted more heavily\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928fb2c-da35-48f4-bab3-f29dcf5b0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_time_effect(entries=['A11-40', 'J-2726','BAR PP 79366'], # plot the list of entries you want\n",
    "                   credit_interval = 0.5, # credit interval\n",
    "                   sort_entries = 'unsorted', # unsorted to keep them in the order listed initially\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d863c-92a0-4fde-95e5-02beadbe1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.loo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac2c93-0951-46a7-a29c-6bc7a825b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_trace(var_names=['rater_severity','tau_rater'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e9d3c-afe1-4983-aad4-0ef7e5b9ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_plot_effect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fc0bc-0bb6-452b-bf54-1f5bcb8ac3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap code, probably wont be used \n",
    "import arviz as az\n",
    "rater_codes = dict(m.df.groupby('RATER')['RATER_CODE'].mean().apply(lambda x: round(x)))\n",
    "inv_rater_codes = {}\n",
    "for key in rater_codes.keys(): inv_rater_codes[rater_codes[key]] = key\n",
    "for i in range(7):\n",
    "    print(inv_rater_codes[i])\n",
    "    az.plot_trace(m.fit.tau_rater[:,i,:].T - m.fit.rater_severity[:,i].T,compact=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088514e-cb85-4960-9bd8-f4d0c5b8887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might turn this into a function in the utility file, but not sure.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(7):\n",
    "    plt.figure(figsize=(6, 2)) \n",
    "    for j in range(8):\n",
    "        sample_data = (m.fit.tau_rater[:,i,:].T - m.fit.rater_severity[:,i].T)[j]\n",
    "        sns.kdeplot(sample_data, linewidth=1, label=\"Threshold \"+str(j+1)+\"|\"+str(j+2)+\" : \"+str(round(sample_data.mean(),2)))\n",
    "    plt.title(inv_rater_codes[i]+\" tau distribution\")\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1.12))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84505183-3589-47f8-8480-a809110c8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def rsm_probability(y, theta, beta, tau):\n",
    "    unsummed = np.concatenate(([0], theta - beta - tau))\n",
    "    #print(unsummed)\n",
    "    probs = softmax(np.cumsum(unsummed))\n",
    "    return probs[y]\n",
    "\n",
    "for r in range(7):\n",
    "    plt.figure(figsize=(5, 3)) \n",
    "    tau = list((m.fit.tau_rater[:,r,:].T).mean(axis=1))\n",
    "    beta = m.fit.rater_severity[:,r].T.mean()\n",
    "    for i in range(9):\n",
    "        plt.plot(np.linspace(-6,6,100), [rsm_probability(i,theta,beta,tau) for theta in np.linspace(-6,6,100)], linewidth=1, label=str(i+1))\n",
    "        #plt.vlines((tau-m.fit.rater_severity[:,1].T.mean())[i],ymin=0, ymax=1)\n",
    "        plt.title(inv_rater_codes[r]+\" category probabilities\")\n",
    "        plt.xlabel('Turf Quality')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b54474-0553-42d1-bc02-4fa9fa5fa189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import bisect\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "lb = -6\n",
    "ub = 6\n",
    "resolution = 100\n",
    "colors = px.colors.diverging.Spectral\n",
    "\n",
    "x_space = np.linspace(lb,ub,resolution)\n",
    "x_data = []\n",
    "\n",
    "for r in range(7):\n",
    "    tau = list((m.fit.tau_rater[:,r,:].T).mean(axis=1))\n",
    "    beta = m.fit.rater_severity[:,r].T.mean()\n",
    "    boundaries = []\n",
    "    for i in range(8):\n",
    "        def probability_difference(x):\n",
    "            return rsm_probability(i+1,x,beta,tau) - rsm_probability(i,x,beta,tau)\n",
    "        #plt.plot(x_space, [probability_difference(theta) for theta in x_space], linewidth=1, label=str(i+1))\n",
    "        boundaries.append(bisect(probability_difference,lb,ub))\n",
    "    stacks = [boundaries[0]-lb]\n",
    "    for i in range(1,8):\n",
    "        stacks.append(max(0,boundaries[i]-max(boundaries[:i])))\n",
    "    stacks.append(max(0,ub-max(boundaries)))\n",
    "    x_data.append(stacks)\n",
    "    #print(sum(stacks))\n",
    "    #print(stacks)\n",
    "    #print(boundaries)\n",
    "x_data = np.array(x_data).T\n",
    "y_data = [inv_rater_codes[i]+\" \" for i in range(7)]\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(9):\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=y_data,\n",
    "        x=x_data[i],\n",
    "        name=str(i+1),\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color=colors[i],\n",
    "            line=dict(color=colors[i], width=3)\n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig.update_layout(barmode='stack',\n",
    "                  title='Most Probable Rating',\n",
    "                  xaxis=dict(title='Turf Quality', range=[0, ub-lb],\n",
    "                              ticktext=[str(i) for i in range(lb,ub+1)],\n",
    "                             tickvals=list(range(0, ub-lb+1))),\n",
    "                  yaxis=dict(title='Rater', automargin=True),)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d453cde-e09b-4c72-a8b1-82c184b300a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = list((m.fit.tau_rater[:,6,:].T + m.fit.rater_severity[:,6].T).mean(axis=1))\n",
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324e22a-5a56-4068-b979-9a6f86cf1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = m.df\n",
    "\n",
    "table = pd.pivot_table(df[['PLT_ID','RATER_CODE','QUALITY']], aggfunc='count',index='QUALITY',columns='RATER_CODE',values='QUALITY')\n",
    "for i in range(7): table[i] = table[i]/sum(table[i])\n",
    "\n",
    "y_data = [inv_rater_codes[i]+\" \" for i in range(7)]\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(9):\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=y_data,\n",
    "        x=table.loc[i+1],\n",
    "        name=str(i+1),\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color=colors[i],\n",
    "            line=dict(color=colors[i], width=3)\n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig.update_layout(barmode='stack',\n",
    "                  title='Rating Proportions',\n",
    "                  xaxis=dict(title='Proportion of Ratings', range=[0,1]),\n",
    "                  yaxis=dict(title='Rater', automargin=True),)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15211f-db7d-4edf-9df5-0f601e0e2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462896ac-d2bd-4743-b021-ea2ac98bafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('QUALITY')['RATER_CODE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab5396-aab5-4646-89b2-d759312db18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.pivot_table(df[['PLT_ID','RATER_CODE','QUALITY']], aggfunc='count',index='QUALITY',columns='RATER_CODE',values='QUALITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe283c5-3d89-47a9-9aae-314f31c23435",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    table[i] = table[i]/sum(table[i])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fbc9d8-93ab-42ce-a37a-e960bbcd41db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3f452-3e87-4f5b-ba67-2d5418a0a83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
